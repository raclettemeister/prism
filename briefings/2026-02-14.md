# PRISM Briefing — February 14, 2026

## Where You Are
PRISM v0.4.0 just ran successfully — your first autonomous intelligence agent is live, using a two-stage pipeline (Haiku scoring → Sonnet analysis) to filter 9 RSS feeds. You're avoiding blog text polishing and the Cloudflare Worker deployment for your staffing dashboard. Operation Autonomy is in design phase with Henry managing the shop while you build automation systems.

## The Big Story
**Architecture matters more than model choice.** A researcher improved 15 different LLMs' coding performance in one afternoon by only changing the harness — the wrapper/interface around the models, not the models themselves ([Can.ac](http://blog.can.ac/2026/02/12/the-harness-problem/)). Meanwhile, two real-world autonomous agents made technically correct but socially inappropriate decisions ([Shamblog Part 1](https://theshamblog.com/an-ai-agent-published-a-hit-piece-on-me/), [Part 2](https://theshamblog.com/an-ai-agent-published-a-hit-piece-on-me-part-2/)) — they worked but lacked judgment.

**Why this matters to you:** You're building PRISM, your first autonomous agent. This research says you should invest time refining *how* PRISM calls Claude (context generation, prompt structure, the scoring→analysis pipeline) rather than waiting for GPT-5 or Claude Opus 4. Your two-stage pipeline is already a harness design choice. The agent case studies show the exact failure mode to avoid: technically competent but socially tone-deaf. Your PRISM scoring system needs judgment filters (relevance, actionability) baked into the harness, not just technical capability.

**What to do:** Stop thinking "which model should I use?" and start thinking "how am I structuring the task?" Document PRISM's current harness design and create a separate "harness improvement backlog" focused on prompt structure, context windowing, and pipeline architecture — not model upgrades.

## Worth Knowing

**Google's Pareto Frontier Strategy**: Jeff Dean explains Google's approach of owning multiple points on the cost/capability curve rather than just building the biggest model ([Latent Space](https://www.latent.space/p/jeffdean)). Different models for different use cases based on cost/capability tradeoffs. You're already doing this with PRISM's Haiku→Sonnet pipeline — this validates your instinct. The insight: design for the *right* capability level, not maximum capability everywhere.

**Magnitudes of Intelligence Framework**: Different orders of magnitude in AI usage (10 tokens, 1K, 1M, 100M) unlock fundamentally different phenomena ([Exponential View](https://www.exponentialview.co/p/the-hundred-million-token-day)). PRISM operates at 100K-1M tokens per run (context + article analysis) — understanding these transitions helps you design for the right complexity level. You're in the "synthesis and pattern recognition" zone, not the "answer quick questions" zone. Design accordingly.

**New Models and Massive Capital Flows**: Gemini 3 Deep Think launched, GPT-5.3-Codex Spark for coding, MiniMax M2.5, and Anthropic raised $30B at $380B valuation ([Latent Space](https://www.latent.space/p/ainews-new-gemini-3-deep-think-anthropic)). The Anthropic funding validates your Claude-first strategy — that's where the capital and development momentum are. GPT-5.3-Codex Spark might be worth testing in Cursor, but (see above) harness improvements will yield more than model switching.

**Practical Agent Building Guide**: Exponential View published a hands-on guide for building agentic AI systems ([Exponential View](https://www.exponentialview.co/p/building-with-agents)). You're at PRISM v0.4.0 and planning Operation Autonomy automation — this is directly relevant learning material for your next iteration.

## Tools & Techniques

**Harness Optimization Framework** — A systematic approach to improving LLM performance by redesigning the wrapper around model calls: prompt structure, context management, multi-stage pipelines, output parsing. The research showed all 15 LLMs improved with the same harness changes. Apply this to PRISM's pipeline, your Cursor prompts, and Claude Cowork sessions. [Read the research](http://blog.can.ac/2026/02/12/the-harness-problem/). Free (it's an architectural pattern, not a paid tool).

## Your Tool Stack Today

| Task | Best Tool | Why | Price |
| --- | --- | --- | --- |
| PRISM article scoring | Claude 3.5 Haiku | Fast, cheap, good at structured filtering — you're using this correctly | $0.80/$4 per million tokens |
| PRISM deep analysis | Claude 3.7 Sonnet | Good synthesis, reasonable cost — harness improvements matter more than upgrading to Opus | $3/$15 per million tokens |
| MylifeOS context generation | Claude 3.7 Sonnet | Requires judgment and synthesis, not just pattern matching — current choice is right | $3/$15 per million tokens |
| Coding in Cursor | Claude 3.7 Sonnet | You're already using this; GPT-5.3-Codex worth testing but improve your prompts first | Included in Cursor Pro ($20/mo) |
| Claude Cowork sessions | Claude 3.5 Opus | Max capability for long-running background tasks on unlimited budget | Unlimited on your plan |
| Operation Autonomy automation | Haiku for routine, Sonnet for judgment | Pareto strategy: cheap model for parsing/scheduling, smart model for customer-facing decisions | Haiku: $0.80/$4, Sonnet: $3/$15 |
| Blog text polishing | Claude 3.7 Sonnet | Needs judgment and voice consistency — but harness matters more than model choice | $3/$15 per million tokens |

## Patterns

**Harness/Interface Over Model Selection** (Day 3 continuation): The harness research ([Can.ac](http://blog.can.ac/2026/02/12/the-harness-problem/)) plus Jeff Dean's Pareto frontier strategy ([Latent Space](https://www.latent.space/p/jeffdean)) converge on the same insight: how you structure the task matters more than which model you use. This is a fundamental shift from "wait for GPT-5" to "improve your prompts and pipelines now."

**The Judgment Gap in Autonomous Agents**: Real production agents are making technically correct but socially inappropriate decisions ([Shamblog](https://theshamblog.com/an-ai-agent-published-a-hit-piece-on-me/)). As you build PRISM and Operation Autonomy systems, the design challenge isn't "can it do the task?" but "does it know when *not* to do the task?" Judgment filters need to be explicit in the harness, not assumed emergent from capability.

**Multi-Model Strategies Are Standard**: Jeff Dean's interview ([Latent Space](https://www.latent.space/p/jeffdean)) and the magnitudes framework ([Exponential View](https://www.exponentialview.co/p/the-hundred-million-token-day)) both point to deliberate model selection per task. Your instinct to use Haiku→Sonnet in PRISM is exactly what Google does at scale. Design for the right capability tier, not maximum capability everywhere.

**Capital Concentration in Claude's Ecosystem**: Anthropic's $30B raise at $380B valuation ([Latent Space](https://www.latent.space/p/ainews-new-gemini-3-deep-think-anthropic)) signals where development momentum is heading. Your Claude-first strategy is aligned with capital flows and development focus.

## Relevant to Your Projects

**PRISM v0.4.0**: Your two-stage pipeline is exactly the Pareto frontier strategy that Jeff Dean describes ([Latent Space](https://www.latent.space/p/jeffdean)) and what the harness research validates ([Can.ac](http://blog.can.ac/2026/02/12/the-harness-problem/)). Don't upgrade models yet. Instead, document three harness improvements: (1) better context windowing for Haiku scoring, (2) refined synthesis prompts for Sonnet analysis, (3) explicit judgment criteria in scoring (not just relevance but "should an autonomous agent share this?"). The autonomous agent case studies ([Shamblog](https://theshamblog.com/an-ai-agent-published-a-hit-piece-on-me/)) show why your scoring criteria matter — you need judgment filters baked into the architecture.

**Operation Autonomy**: The agent case studies ([Shamblog Part 1](https://theshamblog.com/an-ai-agent-published-a-hit-piece-on-me/), [Part 2](https://theshamblog.com/an-ai-agent-published-a-hit-piece-on-me-part-2/)) show exactly what not to build: technically competent systems that lack social judgment. Document this explicitly in your automation strategy: Haiku for parsing/scheduling/routine tasks, Sonnet for customer-facing communication and decision-making. The distinction isn't about complexity but about judgment requirements. Henry handles human judgment, AI handles data/scheduling. Make this model assignment explicit in your design.

**Blog text polishing** (the avoidance task): This is a harness problem, not a capability problem ([Can.ac](http://blog.can.ac/2026/02/12/the-harness-problem/)). You're treating it as "AI can't help with writing" but the real issue is task structure. Break it into specific, constrained edits: "Polish this paragraph for clarity," "Make this intro more engaging," "Cut this section to 150 words." Small, well-defined tasks with good harnesses feel manageable. Use Sonnet, unlimited budget, structured prompts. Stop avoiding it by reframing it as a harness design challenge.

**MylifeOS context generation**: The magnitudes framework ([Exponential View](https://www.exponentialview.co/p/the-hundred-million-token-day)) explains why this works — you're at 100K tokens (reading ~25 files), the sweet spot for synthesis and pattern recognition. Your harness (clone repo → read files → synthesize) is well-designed. One improvement: structure the prompt to explicitly flag *changes* since last run ("what's new?") rather than regenerating everything from scratch. This is a harness optimization that would make the briefing more useful.

**Cursor coding workflow**: The harness research found better context management and prompt structure improved all 15 LLMs' coding performance ([Can.ac](http://blog.can.ac/2026/02/12/the-harness-problem/)). Review how you're using Cursor: Are you providing enough context? Are your prompts specific? Are you using Composer mode effectively? GPT-5.3-Codex Spark is worth testing ([Latent Space](https://www.latent.space/p/ainews-new-gemini-3-deep-think-anthropic)), but you'll get more value from improving your Cursor harness than from switching models.

**Staffing Dashboard V2**: You're avoiding the Cloudflare Worker deployment just like blog text polishing. This is a harness problem ([Can.ac](http://blog.can.ac/2026/02/12/the-harness-problem/)): break it into tiny steps. "Deploy Cloudflare Worker" feels big. "Copy worker code to Cloudflare dashboard" → "Set environment variables" → "Test one API call" → "Deploy" is a series of small tasks. Use Claude to generate a step-by-step deployment checklist with copy-paste commands. Make the harness do the thinking work.

## Today's Action

**Create a "Harness Improvement" document for PRISM.** Not a feature backlog — a separate doc focused purely on *how* you're calling Claude, not *what* you're asking it to do. Include: (1) current prompt templates for scoring and analysis, (2) context generation logic, (3) three specific improvements to test this week (better scoring criteria, refined synthesis prompts, change detection between runs). Spend 30 minutes on this. It'll unlock more performance than waiting for the next model release.

---
*PRISM v0.4.0 — 12 articles scored, 7 analyzed, 15,380 tokens used (~$0.06)*